<!doctype html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

        <title>Privacy-Utility Trade-offs in Sequential Decision-Making under Uncertainty </title>

        <link rel="stylesheet" href="dist/reset.css">
        <link rel="stylesheet" href="dist/reveal.css">
        <!-- <link rel="stylesheet" href="dist/theme/serif.css" id="theme"> -->
        <link rel="stylesheet" href="dist/theme/indigo.css" id="theme">
        <link rel="stylesheet" href="css/custom.css">

        <!-- Theme used for syntax highlighted code -->
        <link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
    </head>
    <body>
        <div class="reveal">
            <div class="slides">


                <!-- First Slide - Title, Author, Topic -->
                <section data-background="white">
                    <section>
                    <header><h4 style="font-size:1.2em">
 Privacy-Utility Trade-offs in Sequential<br> 
 Decision-Making under Uncertainty</h4></header>
                    <p class="authors" style="font-size:0.8em"> 
                        <a href="https://achraf-azize.github.io/">Achraf Azize</a>
                    <p class="authors" style="font-size:0.5em"> 
 Supervised by
                        <a href="https://debabrota-basu.github.io/">Debabrota Basu</a>
 and 
                        <a href="https://philippe-preux.github.io/">Philippe Preux</a>
                    </p>
                    <br>
                    <footer>
                        <img data-src="images/ulille.png" height="75">
                        <img data-src="images/inria.png" height="75">
                        <img data-src="images/cristal.svg" height="75">
                    </footer>

					<aside class="notes">
					</aside>
                    </section>

                    <section>
                        <header><h3>Jury Members</h3></header>
                        <img style="vertical-align:middle" height="500" data-src="images/jury6.svg">
						<aside class="notes">
						</aside>
                    </section>
					
                </section>

                <!-- 

 Context & Motivation 

 -->
                <section>
                    <!-- Header  -->
                    <section>
                        <header><h3>Context & Motivation</h3></header>
                        <br>
                        <span class="smalltext">Privacy in Bandits</span>
                    </section>

                    <section data-background="white">
                        <header><h3>Sequential Decision-Making</h3></header>
                        <br>
                        <ul>
                            <li>Make decisions based on data interactively
                            <li class="fragment">
 Data is sensitive and detailed
                            </li>
                            <li class="fragment">
 Multi-armed Bandits under Differential Privacy
                            </li>
                        </ul>
						
						
                    </section>

                    <section data-background="white">
                        <header><h3>Multi-armed Bandits</h3></header>
                        <br>
                        <img style="vertical-align:middle" height="200" data-src="images/mab.svg">
                        <br>
                        <ul>
                            <li>Learner interacts with an unknown environment </li>
                            <li>Goal: maximize rewards</li>
                        </ul>
                        
                    </section>


                    <section data-background="white">
                        <header><h3>Example: Clinical trials [1]</h3></header>
                        <br>
                        <!-- <img style="vertical-align:middle" height="200" data-src="images/rl_example.svg"> -->
                        <img style="vertical-align:middle" height="200" data-src="images/medicine_bandit.svg">
                        <br>
                        <p> For the $t$-th patient</p>
                        <ol>
                            <li> Doctor chooses medicine $a_t \in \{1, \dots, K\}$</li>
                            <li> If Patient $t$ is cured $r_t = 1$, otherwise $r_t = 0$
                        </ol>
                        <span class="myfootnote">
                            <ul>
 [1] W. R. Thompson.   
                                    <b>On the likelihood that one unknown probability exceeds another in view of the evidence of two samples</b>
 (Biometrika 1933).
                            </ul>
                        </span>


                    </section>
                    <section data-background="white" style="font-size: 31px;"> 
                        <header><h3>Challenge</h3></header>
                        <br>
                        <ul>
                            <li> Protect the privacy of the patients' data: rewards</li>
							<li class="fragment"> By publishing the actions, risk of leaking information about private rewards</li>
                            <li  class="fragment"> Other
 applications: recommender systems, online advertisement, user studies  </li>
                            <!-- <li  class="fragment"> Counterfactual: what can a malicious adversary do? </li> -->
                        </ul>
                        <br>
                        <br>
                        <span class="fragment">
                            <b>Main Question:</b> What is the cost of achieving privacy in bandits?
                            </span>
						
                    </section>

                    <section data-background="white" style="font-size: 28px;">
                        <header><h3>Differential Privacy [1]</h3></header>
                        <br>
                        <b> Intuition:</b> Indistinguishability from the mass
                        <img style="vertical-align:middle" height="270" data-src="images/dp_intuition_curve.svg">
                        <br>
                        <span class="fragment">
                        <span class="theorem">
							$\mathcal{M}$ is $\color{blue}{\epsilon}$-DP if 
							$$
							\forall d\sim d', \, \forall E\in \mathcal{O}, \,  \mathcal{M}_{d}(E) \leq e^{\color{blue}{\epsilon}} \mathcal{M}_{d'}(E)
							$$
                        </span>
						<p > $\color{blue}{\epsilon}$: Privacy budget </p>
                        </span>
                        <span class="myfootnote">
                            <ul>
								[1] C.Dwork, F.McSherry, K.Nissim, A.Smith.  
																	<b>Calibrating noise to sensitivity in private data analysis</b>
								(TCC 2006).
                            </ul>
                        </span>

                    </section>

                    <section data-background="white" style="font-size: 32px;">
                        <header><h3>Differential Privacy</h3></header>

 Several Current Deployments
                        <img style="vertical-align:middle" height="300" data-src="images/dp_dep.svg">

                        <span class="fragment">
                        <br>
                        <b> Privacy Auditing:</b> How to certify privacy/estimate the privacy budget? 
                        </span>

                    </section>
                    
                    <section data-background="white" style="font-size: 30px;">
                        <header><h3>Privacy Auditing</h3></header>
                        <header><h5> using Membership Attacks</h5></header>

						<span class="r-stack">
							<span class="fragment current-visible" data-fragment-index="1"> 
								<b> Intuition:</b> Stronger the attack succeeds, less private is the mechanism
							</span>
								
							<span class="fragment current-visible" data-fragment-index="2"> 
								<b > Membership attacks:</b> Determine if a target datapoint $z^\star$ was in the input $d$
								<br> 	
								<br>
									<img height="300" data-src="images/mia.svg">
							</span>
							

							<span class="fragment current-visible" data-fragment-index="3"> 	
							<img style="vertical-align:middle" height="500" data-src="images/dp_audit.svg">
							<br>
								<b>Main Questions:</b> How to design canaries? How to design optimal attacks?
								
							</span>
							
						</span>

                    </section>

                    <section>
                        <header><h3>Outline</h3></header>
                        <br>
                        <ol>
                            <li>Definitions: privacy and utility in bandits</li>
                            <li class="fragment">Lower bounds: What is the best utility achievable?</li>
                            <li class="fragment">Algorithm design: How to achieve the best utility?</li>
                            <li class="fragment">Revisiting Membership Inference Games</li>
                        </ol>

						
                    </section>
                </section>  <!-- end of context & motivation-->


                <!-- 

 Definitions

 -->
                <section>
                    <!-- Header  -->
                    <section>
                        <header><h3> Definitions </h3></header>
                        <br>
                        <span class="smalltext">
 Bandits: Utility & Privacy
                        </span>
                    </section>

                    
                    <section data-background="white">
                        <header><h3>Stochastic Bandit Interaction</h3></header>
                        <br>
 Sequential interaction between:
                        <ul>
                            <li> a policy $\pi = (\pi_t)_t$ </li>
                            <li> an environment $\nu = (P_a)_{a \in [K]}$, with means $\mu(\nu) = (\mu_a(\nu))_{a \in [K]}$</li>
                        </ul>
                        <br>
                        <br>
                        <span class="fragment">
                        <span class="theorem">
 At step $t$
                        <br>
                        <ol>
                            <li> $a_t \sim \pi_t(. \mid a_1, r_1, \dots, a_{t-1}, r_{t-1})$</li>
                            <li> $r_t \sim P_{a_t}$
                        </ol>
                        </span>
                        </span>

						
                    </section>

                    <section data-background="white">
                        <header><h3>Two Utility Objectives</h3></header>
                        <br>
                        <b>(a) Regret minimisation:</b> Given a horizon $T$, minimise 
                        <span class="fragment">
 $$\mathrm{Reg}_{T}(\pi, \nu) \triangleq T \mu^\star(\nu)-\mathbb{E}_{\nu \pi}\left[\sum_{t=1}^{T} r_{t}\right]$$
 where $\mu^\star(\nu) \triangleq \max\limits_{a \in [K]} \mu_a(\nu)$
                        </span>

						
                    </section>
                    
                    <section data-background="white">
                        <header><h3>Two Utility Objectives</h3></header>
                        <br>
                        <b>(b) Best-arm Identification:</b> Find the optimal arm 
 $a^\star(\nu) \triangleq \arg\max\limits_{a \in [K]} \mu_a(\nu)$
                        <br>
                        
                        <br>
                        <span class="fragment">
 Fixed Confidence: Minimise the number of samples used to identify $a^\star(\nu)$ with confidence $1 - \delta \in (0,1)$
                        </span>

						
                    </section>

                    <section data-background="white">
                        <header><h3>Best-arm Identification</h3></header>
                        <br>
                        <ol> 
                            <li>Stop the bandit interaction at time $\tau$</li> 
                            <li>Recommend a final guess $\widehat{a} \in [K]$</li>
                        <br>
                        <span class="fragment">
                        <span class="theorem">
                            <b>Definition: </b>A strategy is $\delta$-correct for a class $\mathcal{M}$, if

 $$ \mathbb{P}_{\nu, \pi} ( \tau < \infty, \widehat{a} = a^\star(\nu) ) \geq 1 - \delta$$
 for every environment $\nu \in \mathcal{M}$
                        </span>
                        <br>
                        <br>
                        <span class="fragment">
                            <span style="text-align: left; ; font-size: 35px;">
                            <b >Goal:</b> Design a $\delta$-correct strategy, with the smallest $\mathbb{E}_{\pi, \nu} [\tau]$
                        </span>
                        </span>

						
                    </span>
                        
                    </section>

                    <section data-background="white">
                        <header><h3>Two Utility Objectives</h3></header>
                        <br>
                        <b>(a) Regret minimisation: </b> Minimise $\mathrm{Reg}_{T}(\pi, \nu)$
                        <br>
                        <b>(b) FC-BAI: </b> Minimise $\mathbb{E}_{\pi, \nu} [\tau]$ for $\delta$-correct strategies

						
                    </section>

                    <section data-background="white" style="font-size: 30px;">
                        <header><h3>Bandits with DP</h3></header>
                        <br>
                        <p><b>Privacy Constraint:</b> Rewards may contain sensitive information about individuals</p> 
                        <span class="fragment">
                        <img style="vertical-align:middle" height="180" data-src="images/dp_mec2.svg">
                        <br>
 						Ingredients to specify:
                        <br>
						<br>
                        <ul>
                            <li>The randomized mechanism: induced by the policy $\pi$</li>
							<li>The output: sequence of actions </li>
                            <li>The private input dataset </li> 
                        </ul>
                    </span>
					
                    </section>

                    <section data-background="white" style="font-size: 34px;">
                        <header><h3>Table DP</h3></header>
                        <br>
                        <b >Definition:</b> $\pi$ satisfies $\epsilon$-Table DP if $\mathcal{M}^\pi$ is $\epsilon$-DP
                        <img style="float:right" height="450" data-src="images/table_dp_math_plus.svg">
                    </span>

					
                    </section>

                    <section data-background="white" style="font-size: 34px;">
                        <header><h3>View DP</h3></header>
                        <br>
                        <b>Definition:</b> $\pi$ satisfies $\epsilon$-View DP if $\mathcal{V}^\pi$ is $\epsilon$-DP
                        <br>
                        <img style="vertical-align:middle;margin:0px 270px" height="450" data-src="images/view_dp_maths_plus.svg">

                    </span>

					
                    </section>

                    <section data-background="white" style="font-size: 34px;">
                        <header><h3>Comments on the Definitions [$\ast$]</h3></header>
                        <br>
                        <ul>
                            <li> $\pi$ is $\epsilon$-Table DP $ \Leftrightarrow $ $\pi$ is $\epsilon$-View DP</li>
                            <li class="fragment"> For other variants of DP: Table DP $\subset$ View DP</li>
                            <li class="fragment"> For BAI: infinite inputs, output $\{\tau, (a_1, \dots, a_\tau ), \hat{a}\}$</li>
                            <li class="fragment"> Interactive DP: rewards are chosen adaptively by an adversary</li>
                        </ul>
                        <br>
                        <br>
                        <br>
                        <span class="myfootnote" style="font-size: 17px;">
 [$\ast$] <span class="blue2">A. Azize</span>, D. Basu.
                                    <b>Concentrated Differential Privacy for Bandits</b> (SaTML 2024)
                        </span>

						
                    </section>

                    <section style="font-size: 34px;">
                        <header><h3>Objectives</h3></header>
                        <header><h5>Recap</h5></header>
                        <br>
                        <ul>
                            <li> Design an <b>$\epsilon$-DP</b> policy $\pi$ that minimises $\mathrm{Reg}_{T}(\pi, \nu)$ </li>
                            <li> Design an <b>$\epsilon$-DP</b>  <b class="blue">$\delta$-correct</b> strategy $\pi$ that minimises $\mathbb{E}_{\pi, \nu} [\tau]$ </li>
                        </ul>

						
                    </section>

                </section>
                <!-- 

 Lower bounds

 -->
                <section>
                    <!-- Header  -->
                    <section>
                        <header><h3> Lower Bounds </h3></header>
                    </section>
            
                    
                    <section data-background="white" style="font-size: 34px;">
                        <header><h3>Regret Lower Bound</h3></header>
                        <br>
                        <span class="horizental-align:middle">
                        <span class="theorem" style="text-align: left; font-size: 30px;">
                            <b class="blue2">Theorem. </b> For any $\epsilon$-DP policy $\pi$ consistent over a class of environments $\mathcal{M}$
 $$
 \liminf _{T \rightarrow \infty} \frac{\mathrm{Reg}_{T}(\pi, \nu)}{\log (T)} \geq \sum_{a: \Delta_{a}>0} \frac{\Delta_a}{\min \biggl( \underset{\text{without DP}}{\underbrace{\textrm{KL}_\textrm{inf}\left(P_{a}, \mu^\star, \mathcal{M}_a\right)}}, \underset{\text{with $\epsilon$-DP}}{\underbrace{\epsilon \, \textrm{TV}_\textrm{inf}\left(P_{a}, \mu^\star, \mathcal{M}_a\right)}} \biggl)}
 $$
 where $\Delta_a \triangleq \mu^\star - \mu_a$ 
 and $$\textrm{d}_\textrm{inf} (P, \mu^\star, \mathcal{M}) \triangleq \inf_{P' \in \mathcal{M}} \left\{ \textrm{d}(P, P'): \mu(P') > \mu^\star \right\}$$
                        </span>
                    </span>
                        <br>
                        <span class="myfootnote">
 [$\ast$] <span class="blue2">A. Azize</span>, D. Basu.
                                    <b>When Privacy Meets Partial Information: A Refined Analysis of Differentially Private Bandits</b> (NeurIPS 2022).
                        </span>

						

                    </section>

                    <section data-background="white" style="font-size: 25px;">
                        <header><h3>Regret Lower Bound</h3></header>
                        <header><h5>Simplification and Comments</h5></header>
                        <br>
                        <span class="theorem" style="text-align: left; font-size: 25px;">
 $$
 \liminf _{T \rightarrow \infty} \frac{\mathrm{Reg}_{T}(\pi, \nu)}{\log (T)} \geq \sum_{a: \Delta_{a}>0} \frac{\Delta_a}{\min \biggl( d_a, \epsilon t_a \biggl)}
 $$
                        </span>
                        
                        <span class="r-stack">
                        <span class="fragment current-visible" data-fragment-index="1">
                            <br>
                            <br>
                            <ul>
                                <li> $d_a \approx \Delta_a^2$ and $t_a \approx \Delta_a$, the lower bound simplifies to $$\Omega\left(\sum_a \frac{\log(T)}{\min\{ \Delta_a, \epsilon\}}\right)$$</li>
 and retrieves the known lower bound for private Bernoulli bandits [1]</li>
                                
                            </ul>
                            <br>
                            <br>
    
                            <span class="myfootnote" style="font-size: 19px;">
 [1] R. Shariff, O. Sheffet. <b>Differentially Private Contextual Linear Bandits </b> (NeurIPS 2018).
                            </span>
                        </span>
                        
                        
                        <span class="fragment current-visible" data-fragment-index="2"> 
                            <ul>
                                <li> Two hardness regimes: </li>
                                
                                <ul>
                                    <li> A low privacy regime when $\epsilon > \frac{d_a}{t_a} \approx \Delta_a$: non-private lower bound is dominant</li>
                                    <br>
                                    <li> A high privacy regime when $\epsilon \leq \frac{d_a}{t_a}\approx \Delta_a$: private lower bound is dominant</li>
                                </ul>
                            </ul>
                        </span>

						
                    </span>

                    </section>

                    <section data-background="white" style="font-size: 32px;">
                        <header><h3>Sample Complexity Lower Bound</h3></header>
                        <br>
                        <span class="horizental-align:middle">
                        <span class="theorem" style="text-align: left; font-size: 35px;">
                            <b class="blue2">Theorem. </b> For any $\epsilon$-DP $\delta$-correct strategy $\pi$
 $$
 \mathbb{E}_{\boldsymbol{\nu}, \pi}[\tau] \geq \max\big( \underset{\text{without DP}}{\underbrace{T^{\star}_{\mathrm{KL}}(\boldsymbol{\nu})}}, \underset{\text{with $\epsilon$-DP}}{\underbrace{\frac{1}{\epsilon}  T^{\star}_{\mathrm{TV}}(\boldsymbol{\nu})}}\big) \log \left( \frac{1}{3 \delta}\right)
 $$
 where $\left(T^{\star}_{\textbf{d}}(\boldsymbol{\nu}) \right)^{-1} \triangleq \sup _{\omega \in \Sigma_K} \inf _{\boldsymbol{\lambda} \in \operatorname{Alt}(\boldsymbol{\nu})}  \sum_{a=1}^K \omega_a \textbf{d}(\nu_a, \lambda_a)$.
                        </span>
                    </span>
                        <br>
                        <br>
                        <span class="myfootnote">
 [$\ast$] <span class="blue2">A. Azize</span>, M. Jourdan, A. Marjani, D. Basu.
                                    <b>On the Complexity of Differentially Private Best-Arm Identification with Fixed Confidence</b> (NeurIPS 2023).
                        </span>

						

                    </section>

                

                <section data-background="white" style="font-size: 25px;">
                    <header><h3>Sample Complexity Lower Bound</h3></header>
                    <header><h5>Simplification and Comments</h5></header>
                    <br>
                    <span class="theorem" style="text-align: left; font-size: 25px;">
 $$
 \mathbb{E}_{\boldsymbol{\nu}, \pi}[\tau] \geq \max\big( T^{\star}_{\mathrm{KL}}(\boldsymbol{\nu}), \frac{1}{\epsilon}  T^{\star}_{\mathrm{TV}}(\boldsymbol{\nu})\big) \log \left( \frac{1}{3 \delta}\right)
 $$
                    </span>
                    
                        <br>
                        <br>
                        <ul>
                            <li > $T^{\star}_{\mathrm{KL}}(\boldsymbol{\nu}) \approx \sum_{a} \frac{1}{\Delta_a^2}$ and  $T^{\star}_{\mathrm{TV}}(\boldsymbol{\nu}) \approx \sum_{a} \frac{1}{\Delta_a}$ </li>
                            <br>
                            <span class="fragment">
                            <li > Two hardness regimes: </li>
                                
                                <ul>
                                    <li> A low privacy regime when $\epsilon > \frac{T^{\star}_{\mathrm{TV}}(\boldsymbol{\nu})}{T^{\star}_{\mathrm{KL}}(\boldsymbol{\nu})}$: non-private lower bound is dominant</li>
                                    <br>
                                    <li> A high privacy regime when $\epsilon \leq \frac{T^{\star}_{\mathrm{TV}}(\boldsymbol{\nu})}{T^{\star}_{\mathrm{KL}}(\boldsymbol{\nu})}$: private lower bound is dominant</li>
                                </ul>
                            </span>
                        </ul>
                    
						

                    </section>

                    <section data-background="white" style="font-size: 32px;">
                        <header><h3>Lower Bound Proof</b></h3></header>
                        <br>
                        <ul>
                            <li class="fragment">Reduction to hypothesis testing</li>
                            <br>
                            <span class="fragment">
                            <li >Construct two bandit environments that are conflicting:</li>
                            <ul>
                                <li> Actions that are good for one environment are bad for the other </li>
                                <li>The two environments are hard to distinguish </li>
                            </ul>
                            </span>
                            
                        </ul>
                        <br>
                        <br>
                        <p class="fragment"> Privacy as a "stability" constraint: How similar is the sequence of actions when $\pi$ interacts with two environments $\nu$ and $\nu'$?</p>

						
                    </section>

                    <section data-background="white" style="font-size: 24px;">
                        <header><h3>Group Privacy</h3></header>
                        <img height="300" data-src="images/group.svg">
                        <br>
                        <span class="theorem" style="text-align: left;">
                            <b class="blue2"> Theorem. </b> If $\mathcal{M}$ is $\epsilon$-DP
									$$
									\mathcal{M}_{d}(E) \leq e^ {\epsilon d_{\mathrm{Ham}}(d, d')} \mathcal{M}_{d'}(E)
									$$
 $d_{\mathrm{Ham}}(d, d') \triangleq \sum_{t=1}^T \mathbb{1}\left(d_t \neq d'_t\right)$.
                            <br>
                            <br>
                            <span class="fragment">
                            <b class="blue2"> Consequence. </b> $\mathrm{KL}(\mathcal{M}_d, \mathcal{M}_{d'}) \leq \epsilon d_{\mathrm{Ham}}(d, d') $
                        </span>
                        </span>
                        <br>
                        <br>
                        <span class="fragment">
                        <b>Question:</b> What happens when $d$ and $d'$ are stochastically generated?
                        </span>

						
                    </section>

                    <section data-background="white" style="font-size: 30px;">
                        <header><h3>Stochastic Group Privacy</h3></header>
                        <br>
                        <span class="theorem" style="text-align: left;">
                            <b class="blue2"> Definition. </b> Marginal over output, when the dataset is generated using $\mathbb{P}$
 $$
 M^\mathbb{P} (E) \triangleq \int_{d \in \mathcal{X}^T } \mathcal{M}_d\left(E \right) \mathrm{d}\mathbb{P} \left(d\right)
 $$

                        </span>
                        <br>
                        <br>
                        <span class="fragment">
                        <b>Question:</b> For two distributions $\mathbb{P}$ and $\mathbb{Q}$, how to control the quantity $\mathrm{KL}\left(M^\mathbb{P}, M^\mathbb{Q} \right)$?
                        </span>

						
                    </section>


                    <section data-background="white" style="font-size: 30px;">
                        <header><h3>First Attempt</h3></header>
                        <header><h5>Data-processing Inequality</h5></header>
                        <br>
                        <img style="vertical-align:middle;margin:0px 350px" height="300" data-src="images/data_proc_cent.svg">
                        <br>
                        <br>
                        <span class="theorem" style="text-align: left;">
 $$
 \mathrm{KL}\left(M^\mathbb{P}, M^\mathbb{Q} \right) \leq \mathrm{KL}\left(\mathbb{P}, \mathbb{Q} \right)
 $$
                        </span>

						
                    </section>

                    <section data-background="white" style="font-size: 30px;">
                        <header><h3>Second Attempt</h3></header>
                        <header><h5>Couplings</h5></header>
                        <br>
                        <img style="vertical-align:middle;margin:0px 1px" height="300" data-src="images/coupling.svg">
                        <br>
                        <br>
                        <span class="theorem" style="text-align: left;">
 $$
 \mathrm{KL}\left(M^\mathbb{P}, M^\mathbb{Q} \right) \leq \inf_{\mathcal{C} \in \Pi\left( \mathbb{P}, \mathbb{Q} \right)} \mathbb{E}_{(d, d') \sim \mathcal{C}} \left[ \mathrm{KL}\left(\mathcal{M}_d, \mathcal{M}_{d'} \right) \right]
 $$
                        </span>

						
                    </section>

                    <section data-background="white" style="font-size: 30px;">
                        <header><h3>Couplings and Group Privacy </h3></header>
                        <br>
                        <span class="theorem" style="text-align: left;">
 $$
 \mathrm{KL}\left(M^\mathbb{P}, M^\mathbb{Q} \right) \leq \inf_{\mathcal{C} \in \Pi\left( \mathbb{P}, \mathbb{Q} \right)} \mathbb{E}_{(d, d') \sim \mathcal{C}} \left[ \mathrm{KL}\left(\mathcal{M}_d, \mathcal{M}_{d'} \right) \right]
 $$
                        </span>
                        <br>
                        <br>
                        <span class="fragment">
 If $\mathcal{M}$ is $\epsilon$-DP, then $$\mathrm{KL}(\mathcal{M}_d, \mathcal{M}_{d'}) \leq \epsilon d_{\mathrm{Ham}}(d, d')$$
                        </span>
                        <br>
                        <span class="fragment">
 Solve the transport problem
                        <br>
                        <span class="theorem" style="text-align: left;">
 $$
 \inf_{\mathcal{C} \in \Pi\left( \mathbb{P}, \mathbb{Q} \right)} \mathbb{E}_{(d, d') \sim \mathcal{C}} \left[ d_{\mathrm{Ham}}(d, d') \right]
 $$
                        </span>
                    </span>

					
                    </section>

                    <section data-background="white" style="font-size: 27px;">
                        <header><h3>Couplings and Total Variation </h3></header>
                        <header><h5>Product Distributions</h5></header>
                        <br>
                        <span class="theorem" style="text-align: left;">
 There exists a <b>maximal</b> coupling $c_\infty(\mathbb{P}, \mathbb{Q})$ such that 
 $$
 \begin{align}
 \inf_{\mathcal{C} \in \Pi\left( \mathbb{P}, \mathbb{Q} \right)} \mathbb{E}_{(X, Y) \sim \mathcal{C}} \left[\mathbb{1}\left (X \neq Y\right)\right] &= \mathbb{E}_{(X, Y) \sim c_\infty(\mathbb{P}, \mathbb{Q})}\left[\mathbb{1}\left (X \neq Y\right)\right]\\
  &= \mathrm{TV}\left(\mathbb{P}, \mathbb{Q}\right)
  \end{align}
 $$
                        </span>
                        <br>
                        <br>
                        <span class="fragment">
                        <span class="theorem" style="text-align: left;">
 For $\mathbb{P} =\bigotimes_{t = 1}^T \mathbb{P}_{t} $ and $\mathbb{Q} =\bigotimes_{t = 1}^T \mathbb{Q}_{t}$, using $\mathcal{C}_\infty(\mathbb{P}, \mathbb{Q}) \triangleq \bigotimes_{t = 1}^T c_\infty\left(\mathbb{P}_t, \mathbb{Q}_t\right)$:
 $$
 \mathrm{KL}\left(M^\mathbb{P}, M^\mathbb{Q} \right) \leq \epsilon \sum_{t = 1}^T \mathrm{TV}\left(\mathbb{P}_t, \mathbb{Q}_t\right)
 $$
                        </span>
                    </span>

					
                    </section>

                    <section data-background="white" style="font-size: 30px;">
                        <header><h3>Couplings and Total Variation </h3></header>
                        <header><h5>Bandit Interaction</h5></header>
                        <br>
                        <span class="theorem" style="text-align: left;">
                            <b class="blue2"> Theorem.</b>[$\ast$] $\mathbb{M}_{\nu \pi}$ is the marginal over sequence of actions, when $\pi$ interacts with $\nu$. Then, for all $ \nu = (P_a)_{a \in [K]}$ and $\nu' = (P'_a)_{a \in [K]}$
 $$
 \mathrm{KL}\left(\mathbb{M}_{\nu \pi}, \mathbb{M}_{\nu' \pi} \right) \leq \epsilon \mathbb{E}_{\nu \pi} \left[ \sum_{t = 1}^T \mathrm{TV} \left(P_{a_t}, P'_{a_t}\right) \right]
 $$
                        </span>
                        <br>
                        <br>
                        <span class="fragment">
                        <p style="text-align: left;"><b>Proof.</b> Construct a maximally "coupled environment"</p>
                        </span>
                        <br>
                        <span class="myfootnote" style="font-size: 17px;">
 [$\ast$] <span class="blue2">A. Azize</span>, D. Basu.
                                    <b>Concentrated Differential Privacy for Bandits</b> (SaTML 2024)
                        </span>

						

                    </section>

                    <section data-background="white" style="font-size: 32px;">
                        <header><h3>Retrieving the Lower bounds</h3></header>
                        <br>
                        <p style="text-align: left;"> Plugging the KL upper bound into classic lower bound proof, we generate: </p>
                        <ul>
                            <li> Minimax and problem-dependent regret lower bounds</li>
                            <br>
                            <li> Sample complexity lower bound</li>
                            <br>
                            <li> Regret lower bounds under a linear structure</li>
                            <br>
                            <li> Generalisation to zero Concentrated DP</li>
                        </ul>

						
                    </section>
                    
                    <section style="font-size: 35px;">
                        <header><h3>Lower Bounds</h3></header>
                        <header><h5>Recap</h5></header>
                        <br>
                        <ul>
                            <li>Regret lower bounds for $\epsilon$-DP consistent policies is $$\Omega\left(\sum_a \frac{\log(T)}{\min\{ \Delta_a, \epsilon\}}\right)$$</li>
                            
                            <li>Sample complexity lower bound for $\delta$-correct $\epsilon$-DP strategies is $$\Omega\left(\max\left\{ T^{\star}_{\mathrm{KL}}(\boldsymbol{\nu}), \frac{1}{\epsilon}  T^{\star}_{\mathrm{TV}}(\boldsymbol{\nu})\right\} \log \left( \frac{1}{ \delta}\right)\right)$$</li>
                        </ul>

						
                    </section>

                </section> <!-- end of lower bounds -->

                <!-- 

 Algorithm Design

 -->
                <section>
                    <!-- Header  -->
                    <section>
                        <header><h3> Algorithm Design </h3></header>
                    </section>
    
                    <section data-background="white" style="font-size: 30px;">
                        <header><h3>Generic Recipe</h3></header>
						
						<img height="400" data-src="images/generic_recipe2.svg">

						<span class="r-stack">
						<span class="fragment current-visible" data-fragment-index="1">
							<b class="blue3">1.</b> Characterise a sequence of "sufficient" statistics:
							<p>i.e. the sequence of actions only depend on these statistics</p>
						</li>
						</span>

						<span class="fragment current-visible" data-fragment-index="2">
							<b class="blue3">2.</b> Estimate the sequence of "sufficient" statistics privately</li>
                            <ul>
                                <li> Adding calibrated noise </li>
                                <li> Run the algorithm in phases, with forgetting</li>
                            </ul>
						</span>

						<span class="fragment current-visible" data-fragment-index="3">
							<b class="blue3"> 3.</b>  Calibrate for the noise addition in the algorithm </li>
						</span>

						</span>

						

                    </section>

                    <section data-background="white" style="font-size: 30px;">
                        <header><h3>Finite-armed Stochastic Bandits</h3></header>
                        <header><h5>The UCB Algorithm [1]</h5></header>
                        <br>
                        <span class="theorem"> At step $t$, UCB chooses the arm $A_{t} \in \operatorname{argmax}\limits_{a \in [K]} I_a(t-1)$</span>
                        <br>
                        <p>
 where
 $
 I_a(t-1) = \hat{\mu}_a(t - 1) + \sqrt{\frac{\alpha \log(t)}{2 N_a(t - 1)}}
 $
                        </p>
                        <br>
                        <span class="fragment">
                        <span class="theorem">
                            <b class="blue2"> Theorem.</b> $\mathrm{Reg}_{T}(\mathrm{UCB}, \nu) \leq C \sum_{a: \Delta_a > 0} \frac{ \log(T)}{\Delta_a}$
                        </span>
                        </span>
                        <br>
                        <br>
                        <span class="fragment">
                        <b>Question:</b> How to design a near-optimal $\epsilon$-DP version of UCB?
                        </span>

						<br>
						<br>
						<br>
						<span class="myfootnote" style="font-size: 17px;">
							[1] P. Auer, N. Cesa-Bianchi, and P. Fischer.
															   <b>Finite-time analysis of the multiarmed
																bandit problem.</b> (Machine Learning, 2002).
												   </span>

						
                    </section>


                    <section data-background="white" style="font-size: 21px;">
                        <header><h3>AdaP-UCB[$\ast$]</h3></header>
                        <img style="vertical-align:middle" height="300" data-src="images/adap_ucb.svg">
                        <br>
                        <ul>
                            <li class="fragment" data-fragment-index="1"> Compute $A_{\ell} = \operatorname{argmax}_{a} \color{blue}{\operatorname{I}_{a}^{\epsilon}}(t_{\ell} - 1, \alpha)$</li>
                            <li class="fragment" data-fragment-index="2"> Choose arm $A_{\ell}$ until round t such that $N_{A_\ell}(t) = 2N_{A_\ell}(t_{\ell} - 1)$</li>
                            <li class="fragment" data-fragment-index="3"> Update $\operatorname{I}_{a}^{\epsilon}$ using only reward samples from the last episode</li>
                        </ul>
                        <br>
                        <br>
                        <span class="r-stack">
                        <span class="fragment current-visible" data-fragment-index="4">
							<span class="theorem"  style="font-size: 20px;">
 $$\color{blue}{\operatorname{I}_{a}^{\epsilon}}(t_{\ell}, \alpha) \triangleq  \underset{\text{Non-private index}}{\underbrace{\hat{\mu}_{a}^{\ell}  + \sqrt{ \frac{ \alpha \log(t_{\ell})}{ 2\times \frac{1}{2} N_a(t_\ell) } }}} + \underset{\text{Laplace noise}}{\underbrace{\mathrm{Lap} \left( \frac{1}{\epsilon \times \frac{1}{2} N_a(t_\ell)} \right)}} +  \underset{\text{Privacy bonus}}{\underbrace{\frac{\alpha \log( t_{\ell})}{ \epsilon \times \frac{1}{2} N_a(t_\ell )} }}$$
</span>
                        </span>
                        <span class="fragment current-visible" data-fragment-index="5">
                            <span class="theorem">
                                <b class="blue2"> Theorem.</b> AdaP-UCB is $\epsilon$-DP for rewards in $[0,1]$ and for $\alpha > 3$
 $$
 \mathrm{Reg}_{T}(\mathsf{AdaP\text{-}UCB}, \nu) \leq  \sum\limits_{a \colon \Delta_a > 0} \left ( \frac{16 \alpha }{\min\{\Delta_a, \epsilon\}} \log(T) + \frac{3 \alpha}{\alpha - 3} \right )
 $$
                            </span>
                        </span>
                        </span>
                        <span class="myfootnote" style="font-size: 17px;">
 [$\ast$] <span class="blue2">A. Azize</span>, D. Basu.
                                    <b>When Privacy Meets Partial Information: A Refined Analysis of Differentially Private Bandits</b> (NeurIPS 2022).
                        </span>

						
                    </section>

                    <section data-background="white" style="font-size: 30px;">
                        <header><h3>Extension to Other Settings</h3></header>
                        <br>
						<br>
                        
						<span class="r-stack">
                            <span class="fragment current-visible" data-fragment-index="1">
                            FC-BAI [$\ast$]: Top Two algorithms [1]
                            <ul>
								<li> Sequence of "sufficient" statistics  $(\hat \mu_{a}(t))_{t,a}$</li>
								<li> Arm-dependent doubling, with forgetting</li>
                                <li> Re-calibrating the stopping time thresholds for noise addition </li>
                            </ul>
							<br>
							<br>
							<br>
							<span class="myfootnote" style="font-size: 15px;">
                                [$\ast$] <span class="blue2">A. Azize</span>, M. Jourdan, A. Marjani, D. Basu.
                                    <b>On the Complexity of Differentially Private Best-Arm Identification with Fixed Confidence</b> (NeurIPS 2023)
								
                                </span>
                            </span>
                            
                            <span class="fragment current-visible" data-fragment-index="2">
                            Linear Bandits [$\ast$]: similar arms have similar rewards 
                            <ul>
								<li> $a \in \mathbb{R}^d$ and $r_t \triangleq \left\langle\theta^\star, a_{t}\right\rangle+\eta_{t}$ </li>
								<li> Sequence of "sufficient" statistics: estimated $(\hat \theta(t))_{t}$</li>
								<li> Elimination-based algorithms: already runs in independent phases</li>
                                <li> Explore each arm longer due to noise addition </li>
                            </ul>
							<br>
							<br>
							<br>
							<span class="myfootnote" style="font-size: 15px;">
                                [$\ast$] <span class="blue2">A. Azize</span>, D. Basu.
                                    <b>Concentrated Differential Privacy for Bandits</b> (SaTML 2024)
								</span>
                            </span>
                            
                            <span class="fragment current-visible" data-fragment-index="3">
								Contextual Linear Bandits [$\ast$]: the best medicine depends on the patient 
                            <ul>
								<li> $c_t \in \mathbb{R}^d$ is the context and $r_t = \left \langle \theta^\star, \psi(a_t, c_t) \right \rangle + \eta_{t}$ </li>
								<li> Sequence of "sufficient" statistics  $(\hat \theta(t))_{t}$</li>
                                <li> Phase change in LinUCB: doubling of determinant of the design matrix</li>
                                <li> Calibrating the ellipsoid confidence intervals for noise addition</li>
                                <li> The contexts are supposed to be public! </li>
                            </ul>
							<br>
							<br>
							<br>
							<span class="myfootnote" style="font-size: 15px;">
                                [$\ast$] <span class="blue2">A. Azize</span>, D. Basu.
                                    <b>Concentrated Differential Privacy for Bandits</b> (SaTML 2024)
								</span>
                            </span>
                        </span>
					</span>
                        
					
                    </section>

                    <section data-background="white">
                        <header><h3>Experiments</h3></header>
                        
                        <img style="vertical-align:middle" height="500" data-src="images/fig_regimes4.svg">

						
                    </section>

                    <section>
                        <header><h3>Algorithm Design</h3></header>
                        <header><h5>Recap</h5></header>
                        <br>
 Using the same algorithmic blueprint, we design near-optimal private bandit algorithms in different settings

					
                    </section>


                </section> <!-- end of Algorithm Design -->


                <!-- 

 MIG

 -->
                <section>
                    <!-- Header  -->
                    <section>
                        <header><h3> Membership Inference Games </h3></header>
                    </section>


                    <section data-background="white" style="font-size: 28px;">
                        <header><h3>Setting</h3></header>
                        <img style="vertical-align:middle" height="500" data-src="images/mechanism_mia3.svg">
						<br>
						<b>Main question:</b>
                        <br>
 Given $z^\star \in \mathcal{Z}$ and $o \sim \mathcal{M}_D$, is it possible to determine if $z^\star \in  D$? 

						
                    </section>

                    <section data-background="white" style="font-size: 28px;">
                        <header><h3>Motivation</h3></header>
                        <br>
                        <ul>
                            <li> Studied first as a privacy attack</li>
                            <ul>
                                <li>
 [Homer et al., 2008] for the empirical mean
                                </li>
                                <li class="fragment">
 [Shokri et al., 2017] for machine learning
                                </li>
                            </ul>
                            <br>
                            <span class="fragment">
                            <li> Used for privacy auditing </li>
                            <img style="vertical-align:middle;margin:0px 120px" height="350" data-src="images/dp_audit.svg">
                            </span>
                        </ul>
						
					</section>

                    <section data-background="white" style="font-size: 28px;">
    
                        <header><h3>The Membership Inference Game</h3></header>
                        <br>
 A game between:
                        <ul>
                            <li class="fragment" data-fragment-index="1"> A crafter $\mathcal{C}$: entity with access to the input dataset and the mechanism $\mathcal{M}$ </li>
                            <li class="fragment" data-fragment-index="3"> An adversary $\mathcal{A}_{z^\star}$: tries to determine whether $z^\star$ is in the input dataset</li>
                        </ul>
                        <br>
                        <br>
                        
                        <span class="r-stack">
                        <span class="fragment current-visible" data-fragment-index="2">
                        <span class = "theorem"  style="text-align: left;">
 The crafter $\mathcal{C}$:
                            <br>
                            <ul>
                                <li> Input: $\mathcal{M}$, $n$ and $z^\star$, distribution $\mathcal{D}$ </li>
                                <li> Builds dataset $D \sim \bigotimes_{i = 1}^n \mathcal{D}$ </li>
                                <li> Sample $b \sim \mathrm{Ber}\left ( 1/2 \right)$ </li>
                                <li> If $b = 1$:</li>
                                <ul>
                                    <li> Include $z^\star$ in $D$ at a random position </li>
                                </ul>
                                <li> Sample $o \sim \mathcal{M}(D)$</li>
                                <li> Output: $(o, b)$ </li>
                            </ul>
                        </span>
                    </span>
                
                    <span  class="fragment current-visible" data-fragment-index="4">
                        <span class = "theorem" style="text-align: left;">
 The adversary $\mathcal{A}_{z^\star}$:
                            <br>
                            <ul>
                                <li> Input: $o \in \mathcal{O}$ </li>
                                <li> Output: $\hat{b} \sim \mathcal{A}_{z^\star}(o)$, where $\hat{b} \in \{0,1\}$</li>
                            </ul>
                        </span>
                    </span>

                    <span class="fragment current-visible" data-fragment-index="5">
                        <span class = "theorem"  style="text-align: left;">
 The Interaction Protocol:
                            <br>
                            <ul>
                                <li> Input: crafter $\mathcal{C}$, adversary $\mathcal{A}_{z^\star}$, number of rounds $T$</li>
                                <li> For $t = 1, \dots, T$:</li>
                                <ul>
                                    <li> Sample $(o_t, b_t) \sim \mathcal{C}(\mathcal{M}, n, z^\star, \mathcal{D})$
                                    <li> $\hat{b}_t \sim \mathcal{A}_{z^\star}(o_t)$ </li>
                                </ul>
                                <li> Output: $\left\{ \mathbb{1} \left( b_t = \hat{b}_t \right) \right\}_{t = 1}^T$ </li>
                            </ul>
                        </span>
                    </span>
                        </span>
                        
						
                    </section>
    
                    <section data-background="white" style="font-size: 28px;">
                        <header><h3>Performance Metrics</h3></header>
                        <br>
                        <ul>
                            <li>
 The advantage is a recentred accuracy: 
<span class="fragment"> 
 $$\mathrm{Adv}(\mathcal{A}_{z^\star}) \triangleq 2 \mathrm{Pr} [\mathcal{A}_{z^\star}(o) = b ] - 1$$
</span>
                            </li>
                            <br>
                            <li class="fragment">
								The power under significance $\alpha$ is the max TPR at FPR $\alpha$: 
<span class="fragment">						
 $$ \mathrm{Pow}(s, \alpha) \triangleq \max_{\tau \in T_\alpha}  \mathrm{Pr} \left[s(o, z^\star) \geq \tau \mid b = 1\right] $$

 for $\mathcal{A}_{s, \tau, z^\star}(o)  = \mathbb{1} \left( \underset{\text{score}}{\underbrace{s(o, z^\star)}} \geq \tau \right)$
 where  $$T_\alpha \triangleq \left \{ \tau \in \mathbb{R}: \mathrm{Pr} \left[s(o, z^\star) \geq \tau \mid b = 0 \right] \leq \alpha \right \}$$
</span>
                            </li>
                        </ul>

						
                    </section>

                    <section data-background="white" style="font-size: 28px;">
                        <header><h3>Optimal Adversary</h3></header>
                        <header><h5> The Neyman-Pearson Lemma </h5></header>
                        <br>
 MIG can be seen as a hypothesis test:
                        <ul>
                            <li> Under $H_0$, $z^\star$ was "not included", $o \sim p^\mathrm{out}(o \mid z^\star)$ </li>
                            <li> Under $H_1$, $z^\star$ was "included", $o \sim p^\mathrm{in}(o \mid z^\star)$ </li>
                        </ul>
                        <br>
                        <br>
                        <span class="fragment">
 Then, the log-likelihood ratio score is:
 $$
 \ell(o; z^\star) \triangleq \log\left( \frac{p^\mathrm{in}(o \mid z^\star)}{p^\mathrm{out}(o \mid z^\star)} \right)
 $$
                        </span>
                        <span class="fragment">
 The LR-based attacker is: $$\mathcal{A}_{\ell, \tau, z^\star}(o) = \mathbb{1} \left(\ell(o; z^\star) \geq \tau\right)$$
                        </span>
                        <span class="fragment">
 The Bayes attacker is $\mathcal{A}_{\mathrm{Bayes}, z^\star} \triangleq \mathcal{A}_{\ell, 0, z^\star}$.
                        </span>
					
						
			
                    </section>

                    <section data-background="white" style="font-size: 25px;">
                        <header><h3>Leakage by the Optimal Attacker</h3></header>
                        <br>
                        
                        <span class="theorem" style="text-align: left;">
                        <b class="blue2"> Theorem.</b>
                        <br>
                        <ul>
                            <li>$ \forall$ adversary $\mathcal{A}_{z^\star}$:
 $$ \mathrm{Adv}(\mathcal{A}_{z^\star}) \leq  \mathrm{Adv}(\mathcal{A}_{\mathrm{Bayes}, z^\star}) = \mathrm{TV} \left(p^\mathrm{out}(. \mid z^\star), p^\mathrm{in}(. \mid z^\star)\right)$$ </li>
                            <li> $ \forall$ score $s$, $\forall \alpha \in [0,1]$: 
 $$ \mathrm{Pow}(s, \alpha) \leq  \mathrm{Pow}(\ell, \alpha)$$ </li>
                        </ul>
                        </span>
                        <br>
                        <br>
                        <span class="fragment">
                        <span class="theorem" style="text-align: left;">
                        <b> Definition.</b>
 The membership leakage of $z^\star$, for $\mathcal{M}$, under distribution $\mathcal{D}$ is

 $$ 
 \begin{align}
 \xi(z^\star, \mathcal{M}, \mathcal{D}) &\triangleq \mathrm{Adv}(\mathcal{A}_{\mathrm{Bayes}, z^\star}) \\
 &= \mathrm{TV} \left(p^\mathrm{out}(. \mid z^\star), p^\mathrm{in}(. \mid z^\star)\right)
 \end{align}
 $$
                        </span>
                        </span>
                        <br>
                        <br>
                        <span class="fragment">
 How to quantify $\xi(z^\star, \mathcal{M}, \mathcal{D})$?
                        </span>

						
                    </section>

                    <section data-background="white" style="font-size: 26px;">
                        <header><h3>The Empirical Mean </h3></header>
                        <br>
                        <ul>
                            <li> The mechanism:</li>
 $$\left.\begin{matrix}
 z_1 \in \mathbb{R}^d\\ 
 z_2 \in \mathbb{R}^d\\ 
 .\\ 
 . \\
 z_n \in \mathbb{R}^d\\ 
 \end{matrix}\right\} \xrightarrow{\mathcal{M}^\mathrm{emp}}\hat\mu_n  \triangleq \frac{1}{n} \sum_{i = 1}^n z_i \in \mathbb{R}^d $$
                        
                            <li class="fragment"> Assumption on data-generating distribution $\mathcal{D}$:
                                <ul>
                                    <li> Column-wise independent $\mathcal{D} = \bigotimes_{j = 1}^d \mathcal{D}_j$</li>
                                    <li> Population mean $\mu = (\mu_1, \dots, \mu_d) \in \mathbb{R}^d$ </li> 
                                    <li> Covariance $C_\sigma = \mathrm{diag}(\sigma_1^2, \dots, \sigma_d^2) \in \mathbb{R}^{d\times d}$</li>
                                    <li> Finite 4-th moment</li>
                                </ul>
                            </li> 
                            </ul>
                        <br>
                        <br>
                        <span class="fragment">
                            <b > Main tool:</b> Asymptotic normality, when both $n,d \rightarrow \infty$, such that $d/n = \tau$
                        </span>

						
                    </section>

					<section data-background="white" style="font-size: 20px;">
                        <header><h3> Assymptotic distribution of the LR score</h3></header>
                        <br>
                        <span class="theorem"   >
                            <b class="blue2"> Theorem.</b>[$\ast$] For any $\mathcal{D}$ with finite 4-th moment, as $d,n \rightarrow \infty$ s.t. $d/n = \tau$, we show
							<br>
							<br>
							<ul>
								<li>Under $H_0$: $\ell_n(\hat{\mu}_n; z^\star, \mu, C_\sigma )  \rightsquigarrow \mathcal{N}\left(-\frac{1}{2}  \color{blue}{m^\star}, \color{blue}{m^\star} \right)$ </li>
								<br>
								<li>Under $H_1$: $\ell_n(\hat{\mu}_n; z^\star, \mu, C_\sigma )  \rightsquigarrow \mathcal{N}\left(\frac{1}{2}  \color{blue}{m^\star}, \color{blue}{m^\star} \right)$  </li>
							</ul>
						<br>
						<br>
                        </span>
						<br>
						 <br>
                         $ \color{blue}{m^\star} \triangleq\lim_{n,d} \frac{1}{n} \| z^\star - \mu \|^2_{C_\sigma^{-1}} $
                         <br>
						 <img height="300" data-src="images/dist_lr_easy4.svg">
                         <br>
                         <span class="myfootnote" style="font-size: 17px;">
 [$\ast$] <span class="blue2">A. Azize</span>, D. Basu.
                                    <b> Quantifying the target-dependent Membership Leakage </b> (TPDP 2024).
                        </span>

						
                    </section>

					<section data-background="white" style="font-size: 26px;">
                        <header><h3> Assymptotic distribution of the LR score</h3></header>
                        <header><h5> Proof main steps:</h5></header>
                        <br>
                        <ul>
                            <li>
 Edgeworth Expansion of the LR test:
 $$\ell_n(\hat{\mu}_n; z^\star, \mu, C_\sigma) = (z^\star - \mu)^T C_\sigma^{-1}(\hat{\mu}_n - \mu) 
 - \frac{1}{2n} \|z^\star - \mu\|^2_{C_\sigma^{-1}} + o_p(1)$$
                            </li>
                            <li class="fragment">
 Lindeberg-Feller CLT to get the asymptotic distribution of the LR test
                            </li>
                            
                        </ul>
                        <br>

						
                    </section>



                    <section data-background="white" style="font-size: 26px;">
                        <header><h3> Membership Leakage of the Mean</h3></header>
                        <br>
                        <span class="theorem">
                            <b class="blue2"> Theorem.</b>[$\ast$] The asymptotic leakage of $z^\star$ in the empirical mean is:
 $$\lim_{n,d} \xi_n(z^\star, \mathcal{M}^\mathrm{emp}_n, \mathcal{D}) = \Phi\left (\frac{\sqrt{\color{blue}{m^\star}}}{2}\right) - \Phi\left(-\frac{\sqrt{\color{blue}{m^\star}}}{2}\right)$$

                            <br>
 The optimal asymptotic power under significance $\alpha$:
 $$\lim_{n,d} \mathrm{Pow}_n(\ell_n, \alpha, z^\star) = \Phi\left( \Phi^{-1}(\alpha) + \sqrt{\color{blue}{m^\star}}\right)$$
                        </span>
                         <br>
						 <br>
                         <ul>
                            <li> $ \color{blue}{m^\star} \triangleq\lim_{n,d} \frac{1}{n} \| z^\star - \mu \|^2_{C_\sigma^{-1}} $</li>
                            <li> $\Phi$ is the CDF of the standard normal distribution </li>
                         </ul>
                         <br>
						 <br>
						 <b>Proof:</b> Testing between Gaussians
                         <br>
						 <br>
                         <span class="myfootnote" style="font-size: 17px;">
 [$\ast$] <span class="blue2">A. Azize</span>, D. Basu.
                                    <b> Quantifying the target-dependent Membership Leakage </b> (TPDP 2024).
                        </span>
					
						
                    </section>

                    

                    <section data-background="white" style="font-size: 34px;">
                        <header><h3> Membership Leakage in Different Settings</h3></header>
                        <br>
                        <table class="smallertext theorem">
                            <tr>
                                <th>Setting</th>  
                                <th>Leakage Score</th>
                            </tr>
                            <tr>
                                <td>
 Empirical mean </td>
                                <td>
 $\frac{1}{n} \| z^\star - \mu \|_{C_\sigma^{-1}}^2$
                                </td>
                            </tr>
                            <tr>
                                <td> Gaussian Noise $(\gamma > 0)$</td>
                                <td >
 $\frac{\sigma^2}{\sigma^2 + \gamma^2} \frac{1}{n} \| z^\star - \mu \|_{C_\sigma^{-1}}^2$
                                </td>
                            </tr>
                            <tr>
                                <td>Sub-sampling $(\rho < 1)$</td>
                                <td>
 $\frac{\rho}{n} \| z^\star - \mu \|_{C_\sigma^{-1}}^2$
                                </td>
                            </tr>
                            <tr>
                                <td>Target Misspecification</td>
                                <td>
 $\frac{1}{n} \left(z^\star_{\mathrm{targ}} - \mu\right)^T C_\sigma^{-1}\left(z^\star_{\mathrm{true}} - \mu \right)$
                                </td>
                            </tr>
                        </table>
						
                    </section>

                    <section data-background="white">
                        <header><h3> Simulations</h3></header>
						<header><h5> $n = 1000$, $d=5000$</h5></header>
                        <img height="550" data-src="images/sims_mia_mean.svg">
						
						
                    </section>

                    <section style="font-size: 27px;" data-background="white">
                        <header><h3> Beyond Empirical Mean</h3></header>
                        <header><h5> Gradient Descents in Federated Learning</h5></header>

						<span class="fragment" data-fragment-index="1">
                        <img height="350" data-src="images/fl_prot2.svg">
						</span>

                        <span class="r-stack">
                        <span class="fragment current-visible" data-fragment-index="2">
 $$\theta_{t+1} = \theta_t - \eta_t \mathcal{M}(g_{t,1}, \dots, g_{t,1}, g^\star_t)$$
                        </span>

                        <span class="fragment current-visible" data-fragment-index="3">
                        <ul>
                            <li>
 Choose $g^\star_t$ as the gradient with highest estimated $\|g^\star_t - \hat{\mu}^t_0\|^2_{(\hat{C}^t_0)^{-1}} $
                            </li>

                            <li>
 Use Covariance Attack to trace $g^\star_t$: $$(g^\star_t - \hat{\mu}^t_0)^T(\hat{C}^t_0)^{-1}\left( \frac{\theta_{t+1} - \theta_t}{\eta_t} - \hat{\mu}^t_0 \right) $$
                            </li>
                        </ul>
                    </span>
                </span>
				
                    </section>

                    <section data-background="white">
                        <header><h3> Experiments</h3></header>
                        <img height="500" data-src="images/fig_mia_exps3.svg">
						
                    </section>

                    <section>
                        <header><h3> Membership Inference Games<h3></header>
                        <header><h5> Recap </h5></header>
                        <br>
 The Mahalanobis score explains the target-dependent hardness of MIGs against the empirical mean mechanism

							
                    </section>



                </section> <!-- end of MIG -->



                <section>
                    <!-- Conclusion  -->
                    <section>
                        <header><h3>Conclusion & Perspectives</h3></header>
                    </section>
                    
                    <section data-background="white" style="font-size: 35px;">
                        <header><h3>Privacy in Bandits</h3></header>
                        <br>
                        <ol>
                            <li> Definitions: Utility (Regret/BAI), Privacy (Table/View DP)</li>
                            <li> Lower bounds: couplings and optimal transport</li>
                            <li> Generic recipe for algorithm design </li>
                        </ol>
						<br>
						<br>
						<br>
						<span class="fragment">
						<span class="theorem">
							Two regimes of hardness depending on $\epsilon$ and the gaps
						</span>
					</span>
					
                    </section>

                    <section data-background="white" style="font-size: 35px;">
                        <header><h3>Perspectives/Open Problems</h3></header>
                        <br>
                        <ul>
                            <li> Lower bounds: $(\epsilon, \delta)$-DP</li>
                            <li> Matching upper and lower bounds up to the same constant</li>
                            <li> Adversarial bandits under DP</li>
                            <li> Contextual linear bandits when contexts are private [$\ast$]</li>
                        </ul>

						<br>
						<br>
						<span class="myfootnote" style="font-size: 17px;">
							[$\ast$] <span class="blue2">A. Azize</span>, D. Basu.
															   <b> Open Problem: What is the Complexity of Joint Differential Privacy in Linear Contextual Bandits? </b> (COLT 2024).
												   </span>
					
						
                    </section>

                    <section data-background="white" style="font-size: 35px;">
                        <header><h3>Membership Inference Games</h3></header>
                        <br>
                        <ul>
                            <li> Fixed-target MI Games </li>
                            <li> Same conclusions as Gaussian testing when $4$-th moment is finite:
                                <ul>
                                    <li>
 Mahalanobis distance explains the target hardness
                                    </li>
                                    <li>
 Covariance score is the optimal LR test
                                    </li>
                                </ul>
                            </li>
                        </ul>
						
                    </section>

                    <section data-background="white" style="font-size: 35px;">
                        <header><h3>Perspectives</h3></header>
                        <br>
                        <ul>
                            <li> Generalisation to Z-estimators: Regression, MLE, ERM</li>
                            <li> Black-box auditing</li>
                            <li> Auditing online learning algorithms/auditing contextual bandits</li>
                        </ul>
						
                    </section>

                    <section>
                        <header><h3>Thank you!</h3></header>
                    </section>
                </section><!-- end of Conclusion -->

				<section>
					<section>
						<header><h3>Appendix</h3></header>
					</section>

					<section data-background="white">
						<header><h3>Interactive DP</h3></header>
						<br>
						<img style="vertical-align:middle;margin:0px 200px" height="500" data-src="images/interact_adv.svg">
					</section>

					<section data-background="white" style="font-size: 25px;">
						<header><h3>Regret lower bounds under $\epsilon$-DP</h3></header>
						<br>
						<br>
						<table class="smallertext theorem">
                            <tr>
                                <th>Setting</th>  
                                <th>Minimax</th>
								<th>Problem Dependent</th>
                            </tr>
                            <tr>
                                <td>
									Finite-armed bandits </td>
                                <td>
									$\max \biggl(\frac{1}{27} \sqrt{T(K-1)}, \frac{1}{22} \frac{K-1}{\epsilon} \biggr)$
                                </td>
								<td>
									$\sum_{a: \Delta_{a}>0} \frac{\Delta_{a}\log(T)}{ \min (d_a, \epsilon t_a) } $ 
								</td>
                            </tr>
                            <tr>
                                <td> Linear bandits</td>
                                <td >
									$\max \biggl (\frac{\exp (-2)}{8}  d\sqrt{T},  \frac{\exp (-1)}{4} \frac{d}{\epsilon}   \biggr )$
                                </td>
								<td>
									$ \inf _{\alpha \in[0, \infty)^{\mathcal{A}}} \sum_{a \in \mathcal{A}} \alpha(a) \Delta_{a}\log(T) $ <br>
									$\text { s.t. }\|a\|_{H_{\alpha}^{-1}}^{2} \leq 0.5 \Delta_a \min \left (\Delta_{a}, \epsilon \rho(\mathcal{A}) \right )$
								</td>
                            </tr>
                        </table>
						
					</section>

					<section data-background="white" style="font-size: 25px;">
                        <header><h3>Couplings and Group Privacy </h3></header>
						<header><h3>$\rho$-zCDP </h3></header>
                        <br>
                        <span class="theorem" style="text-align: left;">
 $$
 \mathrm{KL}\left(M^\mathbb{P}, M^\mathbb{Q} \right) \leq \inf_{\mathcal{C} \in \Pi\left( \mathbb{P}, \mathbb{Q} \right)} \mathbb{E}_{(d, d') \sim \mathcal{C}} \left[ \mathrm{KL}\left(\mathcal{M}_d, \mathcal{M}_{d'} \right) \right]
 $$
                        </span>
                        <br>
                        <br>
                        
 If $\mathcal{M}$ is $\rho$-zCDP, then $$\mathrm{KL}(\mathcal{M}_d, \mathcal{M}_{d'}) \leq \rho d_{\mathrm{Ham}}(d, d')^2$$
                       
                        <br>
                        
 Solve the transport problem
                        <br>
                        <span class="theorem" style="text-align: left;">
 $$
 \inf_{\mathcal{C} \in \Pi\left( \mathbb{P}, \mathbb{Q} \right)} \mathbb{E}_{(d, d') \sim \mathcal{C}} \left[ d^2_{\mathrm{Ham}}(d, d') \right]
 $$
                        
                    </span>

					
                    </section>

                    <section data-background="white" style="font-size: 27px;">
                        <header><h3>Couplings and Total Variation </h3></header>
						<header><h3>$\rho$-zCDP </h3></header>
                        <br>
                        <br>
                        <span class="theorem" style="text-align: left;">
 For $\mathbb{P} =\bigotimes_{t = 1}^T \mathbb{P}_{t} $ and $\mathbb{Q} =\bigotimes_{t = 1}^T \mathbb{Q}_{t}$, using $\mathcal{C}_\infty(\mathbb{P}, \mathbb{Q}) \triangleq \bigotimes_{t = 1}^T c_\infty\left(\mathbb{P}_t, \mathbb{Q}_t\right)$:
 $$
 \mathrm{KL}\left(M^\mathbb{P}, M^\mathbb{Q} \right) \leq \rho \left( \sum_{t = 1}^T \mathrm{TV}\left(\mathbb{P}_t, \mathbb{Q}_t\right) \right)^2 + \rho  \sum_{t = 1}^T \mathrm{TV}\left(\mathbb{P}_t, \mathbb{Q}_t\right) \left( 1 - \mathrm{TV}\left(\mathbb{P}_t, \mathbb{Q}_t\right)  \right)
 $$
                        </span>
                    

                    </section>


					<section data-background="white"  style="font-size: 27px;">
						<header><h3>Regret lower bounds under $\rho$-Interactive zCDP</h3></header>
						<br>
						<table class="smallertext theorem">
                            <tr>
                                <th></th>  
                                <th>Minimax</th>
                            </tr>
                            <tr>
                                <td>
									Stochastic Multi-armed bandit </td>
                                <td>
									$\max \biggl(\frac{1}{27} \sqrt{T(K-1)}, \frac{1}{124} \sqrt{\frac{K-1}{\rho}} \biggr)$
                                </td>
                            </tr>
                            <tr>
                                <td> Stoachastic Linear bandit</td>
                                <td >
									$\max \biggl (\frac{\exp (-2)}{8}  d\sqrt{T},  \frac{\exp (-2.25)}{4} \frac{d}{\sqrt{\rho}}  \biggr )$
                                </td>
                            </tr>
                        </table>
					</section>

					<section data-background="white" style="font-size: 25px;">
						<header><h3>AdaP-KLUCB</h3></header>

						
						$$\operatorname{I}_{a}^{\epsilon}(t_{\ell} - 1, \alpha)=  \max \left\{q \in[0,1], d\left(  \breve{\mu}_{a,\epsilon}^{\ell, \alpha}: q\right) \leq \frac{\alpha \log( t_{\ell})}{\frac{1}{2} N_a(t_\ell - 1)} \right\}$$
						where the clipped private empirical mean is $$\breve{\mu}_{a,\epsilon}^{\ell, \alpha} = \operatorname{Clip}_{0,1} \left( \hat{\mu}_a^{\ell} + \color{blue}{\mathrm{Lap} \left( \frac{2}{\epsilon N_a(t_\ell - 1)} \right)} + \frac{\alpha \log(t_{\ell})}{ \epsilon \frac{1}{2} N_a(t_\ell - 1)  }  \right).$$
						
						<br>
						
						<b>Regret Analysis:</b>
						$$
							\mathrm{Reg}_{T}(\text{AdaP-KLUCB}, \nu) \leq \sum\limits_{a \colon \Delta_a > 0}\left ( \frac{C_1(\alpha) \Delta_a }{\min\{ \mathrm{kl}(\mu_a, \mu^*) , C_2 \epsilon \Delta_a\}} \log(T) + \frac{3 \alpha}{\alpha - 3} \right )
						$$

					</section>

					<section data-background="white" style="font-size: 25px;">
						<header><h3> Regert bounds under $\rho$-Interactive zCDP</h3></header>

						<br>

						<table class="smallertext theorem">
                            <tr>
                                <th>Bandit Setting</th>  
                                <th>Regret Upper Bound</th>
								<th>Regret Lower Bound</th>
                            </tr>
                            <tr>
                                <td>
									Finite-armed </td>
                                <td>
									$ \mathcal{O}\left(\sqrt{K T \log(T)}\right) + \color{blue}{\mathcal{O} \left( \frac{ K }{\sqrt{\rho}} \sqrt{\log(T)} \right)}$
                                </td>
								<td>
									$\Omega\left(\max \left ( \sqrt{KT}, \color{blue}{\sqrt{\frac{K}{\rho}}} \right) \right)$
								</td>
                            </tr>
                            <tr>
                                <td> Linear</td>
                                <td >
									$\mathcal{O} \left ( \sqrt{d T \log(KT)} \right) + \color{blue}{ \mathcal{O} \left (\frac{d}{\sqrt{\rho}}\log^{\frac{3}{2}}(KT) \right)}$ 
                                </td>
								<td>
									$ \Omega\left(\max \left ( d \sqrt{T}, \color{blue}{\frac{d}{\sqrt{\rho}}} \right) \right)$
								</td>
                            </tr>
							<tr>
								<td> Contextual</td>
								<td>
									$\mathcal{O}\left( d \log(T) \sqrt{T} \right) + \color{blue}{ \mathcal{O} \left ( \frac{d^2}{\sqrt{\rho}} \log^2(T) \right)}$
								</td>
								<td>

								</td>
							</tr>
                        </table>

						<br>
						<br>
<b>Remark:</b> Change of hardness at $\rho \sim \frac{1}{T}$
					</section>

					<section data-background="white" style="font-size: 29px;">
						<header><h3> Joint-DP [1]</h3></header>
						<br>
						<img style="vertical-align:middle;margin:0px 250px" height="480" data-src="images/joint_dp.svg">

						<br>
                            <br>
    
                            <span class="myfootnote" style="font-size: 19px;">
 [1] R. Shariff, O. Sheffet. <b>Differentially Private Contextual Linear Bandits </b> (NeurIPS 2018).
                            </span>

					</section>

					<section  data-background="white">
						<header><h3>Simulations</h3></header>
						<header><h5>Other setting</h5></header>
						<br>
						<img style="vertical-align:middle" height="480" data-src="images/sims_mia_full.svg">
					</section>
				</section>
                <!-- #
 ################################################
 ################################################
 TEMPLATE
 ################################################
 ################################################
 # -->


                <!-- TABLE TEMPLATE -->
                <!--
 <table>
 <tr>
 <th></th>  
 <th>Col 1</th>
 <th>Col 2</th>
 <th>Col 3</th>
 </tr>
 <tr>
 <th>Blabla</th>  
 <td>Data 1</td>
 <td>Data 2</td>
 <td>Data 3</td>
 </tr>
 </table>
 -->

                <!-- SECTION TEMPLATE -->
                    <!--
 <section>
 <header><h3>My section ...</h3></header>
 <br>
 </section>
 -->

                <!-- TWO-COLUMN TEMPLATE -->
                <!-- <div class="row">
 <div class="column"></div>
 <div class="column"></div>
 </div> -->


                <!-- Video -->
                <!-- <video width="480" data-autoplay muted loop data-src="media/max_f_with_reinforce.mp4" type="video/mp4"></video> -->
            </div>
        </div>

        

        <!-- <section>
 <header><h6>Title</h6></header>
 <br></br>
 <small>

 </small>
 </section>   -->
        <!-- --------------------------------------------------------------------- -->
        <!-- --------------------------------------------------------------------- -->
        <!-- --------------------------------------------------------------------- -->

        <script src="dist/reveal.js"></script>
        <script src="plugin/notes/notes.js"></script>
        <script src="plugin/search/search.js"></script>
        <script src="plugin/highlight/highlight.js"></script>
        <script src="plugin/math/math.js"></script>
        <script src="plugin/zoom/zoom.js"></script>
        <script async defer src="https://buttons.github.io/buttons.js"></script>
        <script>
            // More info about initialization & config:
            // - https://revealjs.com/initialization/
            // - https://revealjs.com/config/
            Reveal.initialize({
                // I (Omar) modified default width/height. Be careful!
                // See https://revealjs.com/presentation-size/
                width: 1080,
                height: 700,
                hash: true,
                slideNumber: true,
                math: {
                    mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
                    config: 'TeX-AMS_HTML-full',
                  // pass other options into `MathJax.Hub.Config()`
                  TeX: { Macros: {
                      Real: "{\\mathbb{R}}",
                      expectedvalue: "\\mathop{\\mathbb{E}}",
                      sigmacovSA: "\\left| \\color{red}{\\mathcal{C}_{\\sigma}}\\right| ",
                      sigmacovS: "\\left| \\color{red}{\\mathcal{C}_{\\sigma}'}\\right| ",
                      epscovSA: "\\left| \\color{red}{\\mathcal{C}_{\\varepsilon}}\\right| ",

 }}
 },
                // Learn about plugins: https://revealjs.com/plugins/
                plugins: [ RevealSearch, RevealHighlight, RevealNotes, RevealMath, RevealZoom ]
 });
        </script>
    </body>
</html>
